1. UNITS_IN_LSTM_LAYER
    See the number of parameters used for each UNITS_IN_LSTM_LAYER

2. Attention mechanism after to extract features from concatenated hidden states

3. Custom training accuracy and loss

4. See for which sentences it is not doing good (Broader)
    After doing that see individual words doing bad

    i.e. first count the number of errors / no of words in sentence
        Do inference from high ratio to low ratio

5. Inference

6. Confusion matrix

7. How to connect to tensorboard

8. Check how much vanishing gradients happen for long seequences of sentences compared to shorter seqeuence of sentences.
    Check how low the gradients are for long sequence inputs

    (Slide 48) of 05_rnns.pdf says long term components goes exponentially fast to norm 0    

    Check in which cases it explodes VS which cases it underflows and becomes 0

9. 



*** Check how to print correct validation and test accuracy
    If we can fix this, the model itself can improve on its own ig

*** Something with the model itself I feel
    It can accept None as the first shape, then it must be BATCH_SIZE as the second dimension of the first layer shape right

*** 